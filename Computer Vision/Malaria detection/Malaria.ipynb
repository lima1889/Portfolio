{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2d49ab8",
   "metadata": {},
   "source": [
    "### Import the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cf525af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-20 09:51:53.626525: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-02-20 09:51:53.626543: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912ffdb7",
   "metadata": {},
   "source": [
    "### Define the features for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c573dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "batch_size = 32\n",
    "num_epochs = 20\n",
    "img_w = 115\n",
    "img_h = 160\n",
    "img_size = 160\n",
    "log_dir = './log'\n",
    "shuffle_buffer_size = 1024\n",
    "img_channels = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9bce77",
   "metadata": {},
   "source": [
    "### Create functions for preprocessing and augmentation of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f217b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(ds):\n",
    "    x = tf.image.resize_with_pad(ds['image'], img_size, img_size)\n",
    "    x = tf.cast(x, tf.float32)\n",
    "    x = (x/127.5) - 1\n",
    "    return x, ds['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "060f9112",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augmentation(image, label):\n",
    "    image = tf.image.random_brightness(image, .1)\n",
    "    image = tf.image.random_contrast(image, lower = 0.0, upper = 1.0)\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3306a3e0",
   "metadata": {},
   "source": [
    "### Create a function to get the dataset and break into train, validation and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40940e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(dataset_name):\n",
    "    train, info_train = tfds.load(dataset_name, split = 'train[:80%]', with_info = True)\n",
    "    val, info_val = tfds.load(dataset_name, split = 'train[80%:90%]', with_info = True)\n",
    "    test, info_test = tfds.load(dataset_name, split = 'train[90%:]', with_info = True)\n",
    "\n",
    "    num_classes = info_train.features['label'].num_classes\n",
    "    assert num_classes >= info_val.features['label'].num_classes\n",
    "    num_examples = info_train.splits['train'].num_examples * 0.9\n",
    "    img_h, img_w, img_channels = info_train.features['image'].shape\n",
    "    \n",
    "    train = train.map(preprocess).shuffle(shuffle_buffer_size).batch(batch_size).cache().repeat()\n",
    "    train = train.map(augmentation)\n",
    "    train = train.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    \n",
    "    val = val.map(preprocess).batch(batch_size).cache().repeat()\n",
    "    val = val.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    \n",
    "    test = test.map(preprocess).batch(batch_size)\n",
    "    test = test.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    \n",
    "    return train, info_train, val, info_val, test, info_test, img_h, img_w, img_channels, num_classes, num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "110500b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-20 09:51:56.414186: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-02-20 09:51:56.414211: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-02-20 09:51:56.414225: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (guilherme-dell): /proc/driver/nvidia/version does not exist\n",
      "2022-02-20 09:51:56.414612: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "train, info_train, val, info_val, test, info_test, img_h, img_w, img_channels, num_classes, num_examples = get_dataset('malaria')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929652ae",
   "metadata": {},
   "source": [
    "### Create the function for the CNN model defining the layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3817946b",
   "metadata": {},
   "source": [
    "This is a very common structure for CNN using the Keras Sequential class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7cc4f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv2D(32, (3, 3), activation = 'relu', input_shape = (img_size, img_size, img_channels))\n",
    "        , tf.keras.layers.MaxPool2D(pool_size = (2, 2))\n",
    "        , tf.keras.layers.Conv2D(32, (3, 3), activation = 'relu')\n",
    "        , tf.keras.layers.MaxPool2D(pool_size = (2, 2))\n",
    "        , tf.keras.layers.Conv2D(32, (3, 3), activation = 'relu')\n",
    "        , tf.keras.layers.Dropout(rate = 0.3)\n",
    "        , tf.keras.layers.Flatten()\n",
    "        , tf.keras.layers.Dense(128, activation = 'relu')\n",
    "        , tf.keras.layers.Dropout(rate = 0.3)\n",
    "        , tf.keras.layers.Dense(num_classes, activation = 'softmax')\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95eccb74",
   "metadata": {},
   "source": [
    "### Create the function to parse the train and val tests, compile and fit the model as defined in the previous function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d858cc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_fit(train, val, learning_rate):\n",
    "    model = create_model()\n",
    "    \n",
    "    model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "                  , loss = 'sparse_categorical_crossentropy'\n",
    "                  , metrics = ['accuracy'])\n",
    "    \n",
    "    earlystop_callback = tf.keras.callbacks.EarlyStopping(monitor = 'val_accuracy'\n",
    "                                                          , min_delta = 0.0001\n",
    "                                                          , patience = 4)\n",
    "    \n",
    "    model.fit(train\n",
    "              , epochs = num_epochs\n",
    "              , steps_per_epoch = int(num_examples/batch_size)\n",
    "              , validation_data = val\n",
    "              , validation_steps = 1\n",
    "              , validation_freq = 1\n",
    "              , callbacks = [earlystop_callback])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29274a15",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-20 09:51:58.305028: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 102252544 exceeds 10% of free system memory.\n",
      "2022-02-20 09:51:58.683583: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 34151040 exceeds 10% of free system memory.\n",
      "2022-02-20 09:51:58.976218: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 51126272 exceeds 10% of free system memory.\n",
      "2022-02-20 09:51:58.976302: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 102252544 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  1/775 [..............................] - ETA: 28:14 - loss: 0.6999 - accuracy: 0.4375"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-20 09:51:59.206870: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 102252544 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "775/775 [==============================] - 600s 772ms/step - loss: 0.4894 - accuracy: 0.7539 - val_loss: 0.1653 - val_accuracy: 0.9375\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-20 10:01:56.965822: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "775/775 [==============================] - 590s 760ms/step - loss: 0.2877 - accuracy: 0.8820 - val_loss: 0.2084 - val_accuracy: 0.9062\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-20 10:11:47.054620: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "775/775 [==============================] - 600s 774ms/step - loss: 0.2357 - accuracy: 0.9124 - val_loss: 0.2345 - val_accuracy: 0.9375\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-20 10:21:46.800179: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "775/775 [==============================] - 615s 794ms/step - loss: 0.2076 - accuracy: 0.9227 - val_loss: 0.6008 - val_accuracy: 0.9375\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-20 10:32:01.838991: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "775/775 [==============================] - 591s 761ms/step - loss: 0.1963 - accuracy: 0.9276 - val_loss: 0.4117 - val_accuracy: 0.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-20 10:41:53.115118: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "model = compile_fit(train, val, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b09af113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 158, 158, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 79, 79, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 77, 77, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 38, 38, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 36, 36, 32)        9248      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 36, 36, 32)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 41472)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               5308544   \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,328,194\n",
      "Trainable params: 5,328,194\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db5248b",
   "metadata": {},
   "source": [
    "Save the model file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9ce0f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('malaria_two.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517153db",
   "metadata": {},
   "source": [
    "### Evaluate the model on unseen data with our test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69917a71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 15s 164ms/step - loss: 0.2094 - accuracy: 0.9525\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2093624770641327, 0.9524673223495483]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4eb79af",
   "metadata": {},
   "source": [
    "Here we see that although our loss is moderately high because of the low number of samples, we got 95.2% accuracy on the test data, which is very good for a CNN trained on a dataset of just around 25k images."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
